{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yavuzssvr19/moodle-chatbot/blob/main/chatbot_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9hRlkpvuJOF"
      },
      "outputs": [],
      "source": [
        "%pip install chromadb --quiet\n",
        "%pip install sentence_transformers --quiet\n",
        "%pip install pypdf --quiet\n",
        "%pip install langchain --quiet\n",
        "%pip install tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MHdIhvvdu46s"
      },
      "outputs": [],
      "source": [
        "\n",
        "import langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
        "\n",
        "\n",
        "from pypdf import PdfReader\n",
        "\n",
        "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
        "from chromadb import Client, PersistentClient\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1QJ1RmwRtKP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYKYEf8EbnFV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chromaDB_path = '/content/drive/MyDrive/RAG_heading_chunks'"
      ],
      "metadata": {
        "id": "Gp2oPVpv_C1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDH8Rck9v22X"
      },
      "outputs": [],
      "source": [
        "#KlasÃ¶r varsa kullanÄ±cÄ±dan izin alarak iÃ§eriÄŸini temizler.\n",
        "# Temiz veri deposu baÅŸlatmak iÃ§in gerekli\n",
        "\n",
        "def delete_all_files_and_folders(chromaDB_path):\n",
        "  # verdiÄŸin klasÃ¶r yolu var mÄ± yok mu kontrol eder.\n",
        "  if os.path.exists(chromaDB_path):\n",
        "    print(f\"The directory '{chromaDB_path}' already exists.\")\n",
        "    permission = input(\"Do you want to delete all the files and folders in this directory? (y/n): \")\n",
        "    #y yazarsa silinsin\n",
        "    if permission == \"y\":\n",
        "      shutil.rmtree(chromaDB_path)\n",
        "      print(f\"All files and folders in '{chromaDB_path}' have been deleted.\")\n",
        "    else:\n",
        "      print(\"No action taken.\")\n",
        "  else:\n",
        "    print(f\"The directory '{chromaDB_path}' does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agbhEiPowEfu"
      },
      "outputs": [],
      "source": [
        "# Check if the chromadb_path exists or not. If so, delete all the files and folders in chromadb_path. But before deleting get the permission from the user.\n",
        "delete_all_files_and_folders(chromaDB_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub55w7rBwI4x"
      },
      "outputs": [],
      "source": [
        "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
        "from chromadb import Client, PersistentClient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM2OCZuBxDRD"
      },
      "source": [
        "collection_name: OluÅŸturulacak veya yÃ¼klenecek koleksiyonun adÄ±\n",
        "\n",
        "embedding_function: Embedding (vektÃ¶rleÅŸtirme) fonksiyonu (Ã¶rneÄŸin: SentenceTransformers gibi)\n",
        "\n",
        "chromaDB_path: EÄŸer belirtilirse Chroma'nÄ±n verileri bu dizine kalÄ±cÄ± olarak kaydedilecek; belirtilmezse geÃ§ici bellek iÃ§inde tutulur.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAmI2rqSDyPy"
      },
      "source": [
        "| Parametre            | AnlamÄ±                | Ne iÅŸe yarar?                                        |\n",
        "| -------------------- | --------------------- | ---------------------------------------------------- |\n",
        "| `collection_name`    | Koleksiyon adÄ±        | Belge koleksiyonu tanÄ±mlar veya yÃ¼kler               |\n",
        "| `embedding_function` | VektÃ¶rleÅŸtirme iÅŸlevi | Metni embedding'e Ã§evirir                            |\n",
        "| `chromaDB_path`      | KayÄ±t yolu            | Verileri kalÄ±cÄ± mÄ±, geÃ§ici mi saklayacaÄŸÄ±nÄ± belirler |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOlMVv7LEk3F"
      },
      "source": [
        "# create_chroma_client\n",
        " ChromaDB istemcisini (client) oluÅŸturur ve bir koleksiyon (collection) yÃ¼kler veya oluÅŸturur.\n",
        "\n",
        "**Ne Zaman KullanÄ±lÄ±r?**\n",
        "- RAG sisteminde PDF metinlerini iÅŸledikten sonra embeddingâ€™leri bir vektÃ¶r veritabanÄ±na (ChromaDB) kaydetmek istersin.\n",
        "\n",
        "- Bu fonksiyon, ChromaDBâ€™yi ya kalÄ±cÄ± olarak (Ã¶rneÄŸin Google Drive klasÃ¶rÃ¼ne) ya da geÃ§ici olarak (RAM iÃ§inde) baÅŸlatmanÄ± saÄŸlar.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb import Client, PersistentClient\n",
        "from chromadb.config import Settings, DEFAULT_TENANT, DEFAULT_DATABASE\n",
        "\n",
        "def create_chroma_client(collection_name, embedding_function, chromaDB_path=None):\n",
        "    if chromaDB_path:\n",
        "        chroma_client = PersistentClient(\n",
        "            path=chromaDB_path,\n",
        "            settings=Settings(),\n",
        "            tenant=DEFAULT_TENANT,\n",
        "            database=DEFAULT_DATABASE\n",
        "        )\n",
        "    else:\n",
        "        chroma_client = Client()\n",
        "\n",
        "    chroma_collection = chroma_client.get_or_create_collection(\n",
        "        name=collection_name,\n",
        "        embedding_function=embedding_function\n",
        "    )\n",
        "    return chroma_client, chroma_collection\n"
      ],
      "metadata": {
        "id": "-UC-WNkG7RWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from chromadb import PersistentClient\n",
        "from chromadb.config import Settings\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# Yeni ve yazÄ±labilir bir klasÃ¶r yolu belirle\n",
        "#chromaDB_path = \"/content/chroma_clean_workspace\"  # RAM iÃ§inde\n",
        "chromaDB_path = '/content/drive/MyDrive/RAG_heading_chunks'\n",
        "\n",
        "# Ã–nce varsa silip temizle\n",
        "if os.path.exists(chromaDB_path):\n",
        "    shutil.rmtree(chromaDB_path)\n",
        "os.makedirs(chromaDB_path, exist_ok=True)\n",
        "\n",
        "# Embedding fonksiyonu tanÄ±mla\n",
        "sentence_transformer_model = \"paraphrase-multilingual-mpnet-base-v2\"\n",
        "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=sentence_transformer_model\n",
        ")\n",
        "\n",
        "# Yeni client baÅŸlat\n",
        "chroma_client = PersistentClient(path=chromaDB_path, settings=Settings())\n",
        "\n",
        "# Yeni koleksiyon oluÅŸtur\n",
        "collection_name = \"Papers_heading_chunks_BERNA\"\n",
        "chroma_collection = chroma_client.get_or_create_collection(\n",
        "    name=collection_name,\n",
        "    embedding_function=embedding_function\n",
        ")\n",
        "\n",
        "print(\"âœ… Yeni koleksiyon baÅŸarÄ±yla oluÅŸturuldu:\", chroma_collection.name)\n"
      ],
      "metadata": {
        "id": "DN1U_a9T6aot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKVtz9wRw82E"
      },
      "outputs": [],
      "source": [
        "#Bu isim, ChromaDB iÃ§inde bir belge koleksiyonunu tanÄ±mlamak iÃ§in kullanÄ±lÄ±r.\n",
        "#bu collection, PDFâ€™lerden Ã§Ä±karÄ±lmÄ±ÅŸ chunklara ait vektÃ¶r verilerini saklayacak.\n",
        "#collection_name = \"Papers_heading_chunks\"\n",
        "\n",
        "#Bu satÄ±rda embedding iÃ§in kullanÄ±lacak modelin ismi belirleniyor.\n",
        "#sentence_transformer_model=\"paraphrase-multilingual-mpnet-base-v2\"\n",
        "\n",
        "#embedding fonksiyonu tanÄ±mlanÄ±yor\n",
        "#Bu fonksiyon, her metin parÃ§asÄ±nÄ± yukarÄ±da belirlenen modeli kullanarak vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "#embedding_function= embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "#    model_name=sentence_transformer_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_bMfIdTe_nX"
      },
      "outputs": [],
      "source": [
        "from chromadb import PersistentClient\n",
        "from chromadb.config import Settings, DEFAULT_TENANT, DEFAULT_DATABASE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QibT24-x3pJ"
      },
      "outputs": [],
      "source": [
        "#Daha Ã¶nce tanÄ±mlanmÄ±ÅŸ create_chroma_client() fonksiyonunu Ã§aÄŸÄ±rÄ±r ve dÃ¶nen iki deÄŸeri chroma_client ve chroma_collection olarak saklar.\n",
        "chroma_client, chroma_collection = create_chroma_client(collection_name,\n",
        "                                                        embedding_function,\n",
        "                                                        chromaDB_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chroma istemcisinden tÃ¼m koleksiyonlarÄ± listele\n",
        "for collection in chroma_client.list_collections():\n",
        "    print(collection.name)\n"
      ],
      "metadata": {
        "id": "tWXM2BuC3DfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"âœ… Koleksiyon adÄ±:\", chroma_collection.name)\n",
        "print(\"âœ… Chunk sayÄ±sÄ±:\", chroma_collection.count())\n"
      ],
      "metadata": {
        "id": "AZj7I3ny7cq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M31n3VF5yect"
      },
      "source": [
        "# upload_multiple_files()\n",
        " KullanÄ±cÄ±nÄ±n Colab arayÃ¼zÃ¼ Ã¼zerinden birden fazla dosya seÃ§ip yÃ¼klemesini saÄŸlar ve yÃ¼klenen tÃ¼m dosyalarÄ±n isimlerini bir liste halinde dÃ¶ndÃ¼rÃ¼r."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsW_YmCJyJ01"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "def upload_multiple_files():\n",
        "  uploaded = files.upload()\n",
        "  file_names = list()\n",
        "  for fn in uploaded.keys():\n",
        "    #print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "    file_names.append(fn)\n",
        "  return file_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgRagzNUzN7q"
      },
      "outputs": [],
      "source": [
        "#Google Colab arayÃ¼zÃ¼nde bir dosya yÃ¼kleme penceresi aÃ§ar.\n",
        "#file_names = upload_multiple_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZbG77QxJTeX"
      },
      "source": [
        "# convert_PDF_Text()\n",
        "-  Bir PDF dosyasÄ±nÄ± sayfa sayfa okuyup, her sayfadaki metni Ã§Ä±karmaktÄ±r.\n",
        "- Her sayfanÄ±n metnini bir liste elemanÄ± olarak saklar ve boÅŸ sayfalarÄ± filtreler.\n",
        "\n",
        ".extract_text(): Sayfadaki metni Ã§Ä±karÄ±r.\n",
        "\n",
        ".strip(): BaÅŸÄ±nda ve sonundaki boÅŸluk karakterlerini siler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkkTAZYpyjwI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_PDF_Text(pdf_path):\n",
        "  reader = PdfReader(pdf_path)\n",
        "  pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
        "  # Filter the empty strings\n",
        "  pdf_texts = [text for text in pdf_texts if text]\n",
        "  print(\"Document: \",pdf_path,\" chunk size: \", len(pdf_texts))\n",
        "  return pdf_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmxeXbDoKg32"
      },
      "source": [
        "# split_by_headings(pdf_texts)\n",
        "PDF'den Ã§Ä±karÄ±lmÄ±ÅŸ dÃ¼z metinleri, baÅŸlÄ±klara gÃ¶re bÃ¶lmek\n",
        "ðŸ“Œ Ã–rneÄŸin: \"1. GiriÅŸ\", \"2.1 Sosyal GeliÅŸim\", \"BÃ¶lÃ¼m 3\", \"SonuÃ§\" gibi baÅŸlÄ±klar yakalanÄ±r ve o baÅŸlÄ±ktan itibaren gelen iÃ§erik bir parÃ§a (chunk) olur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js9BPoVnMsVx"
      },
      "outputs": [],
      "source": [
        "def split_by_headings(pdf_texts):\n",
        "    all_text = \"\\n\".join(pdf_texts)\n",
        "    lines = all_text.split(\"\\n\")\n",
        "    split_points = [i for i, line in enumerate(lines) if re.match(r\"^\\s*(\\d+(\\.\\d+)*|BÃ¶lÃ¼m \\d+|GiriÅŸ|SonuÃ§)\", line, re.IGNORECASE)]\n",
        "\n",
        "    if not split_points:\n",
        "        # fallback: baÅŸlÄ±k bulunamadÄ±ysa tÃ¼m metni tek parÃ§a dÃ¶ndÃ¼r\n",
        "        return [all_text.strip()]\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(len(split_points)):\n",
        "        start = split_points[i]\n",
        "        end = split_points[i + 1] if i + 1 < len(split_points) else len(lines)\n",
        "        section = \"\\n\".join(lines[start:end]).strip()\n",
        "        if section:\n",
        "            chunks.append(section)\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFYDUriby04p"
      },
      "outputs": [],
      "source": [
        "def convert_Page_ChunkinChar_with_pages(pdf_texts, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Heading-aware + character-based chunking:\n",
        "    Ã–nce baÅŸlÄ±klara gÃ¶re ayÄ±rÄ±r, ardÄ±ndan karakter limitine gÃ¶re chunkâ€™lar Ã¼retir.\n",
        "    Sayfa numarasÄ± bilgisi vermez.\n",
        "    \"\"\"\n",
        "    character_splitter = RecursiveCharacterTextSplitter(\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "\n",
        "    # Heading bazlÄ± bÃ¶lÃ¼mleri al (senin split_by_headings fonksiyonunla)\n",
        "    heading_sections = split_by_headings(pdf_texts)\n",
        "\n",
        "    all_chunks = []\n",
        "    for section in heading_sections:\n",
        "        sub_chunks = character_splitter.split_text(section)\n",
        "        all_chunks.extend(sub_chunks)\n",
        "\n",
        "    print(f\"Toplam karakter + heading-aware chunk sayÄ±sÄ±: {len(all_chunks)}\")\n",
        "    return all_chunks, None  # page_numbers yerine None dÃ¶ner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8KAi0X-1OmH"
      },
      "source": [
        "* daha Ã¶nce karakter bazlÄ± olarak bÃ¶lÃ¼nmÃ¼ÅŸ metinleri token bazlÄ± daha hassas parÃ§alara ayÄ±rmak ve LLM veya embedding modellerinin token sÄ±nÄ±rlarÄ±na daha uygun hale getirmekti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRVFa53BzySt"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_Chunk_Token(text_chunksinChar, sentence_transformer_model,\n",
        "                        chunk_overlap=64, tokens_per_chunk=128):\n",
        "  token_splitter = SentenceTransformersTokenTextSplitter(\n",
        "      chunk_overlap=chunk_overlap,\n",
        "      model_name=sentence_transformer_model,\n",
        "      tokens_per_chunk=tokens_per_chunk)\n",
        "\n",
        "  text_chunksinTokens = []\n",
        "  for text in text_chunksinChar:\n",
        "      text_chunksinTokens += token_splitter.split_text(text)\n",
        "  print(f\"\\nTotal number of token chunks: {len(text_chunksinTokens)}\")\n",
        "  return text_chunksinTokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YwBan2w2ATW"
      },
      "source": [
        "Bu fonksiyonun amacÄ±, ChromaDBâ€™ye eklenecek her metin parÃ§asÄ± (chunk) iÃ§in:\n",
        "\n",
        "    * Benzersiz bir kimlik (ID) oluÅŸturmak\n",
        "\n",
        "    * Her parÃ§aya belgeye Ã¶zel metadata (baÅŸlÄ±k ve kategori gibi) eklemek\n",
        "\n",
        "bÃ¶ylece daha sonra belge bazlÄ± filtreleme ve sorgulama yapabilmeni saÄŸlamaktÄ±r."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_bjQ1g61RuN"
      },
      "outputs": [],
      "source": [
        "def add_meta_data(text_chunks, title, category, initial_id, headings=None):\n",
        "    ids = [str(i + initial_id) for i in range(len(text_chunks))]\n",
        "    metadatas = []\n",
        "    for i in range(len(text_chunks)):\n",
        "        meta = {\n",
        "            'document': title,\n",
        "            'category': category\n",
        "        }\n",
        "        if headings:\n",
        "            meta[\"heading\"] = headings[i]\n",
        "            meta[\"source\"] = f\"{title} â€“ {headings[i]}\"  # ðŸ‘ˆ metin formatÄ±nda kaynak\n",
        "        else:\n",
        "            meta[\"source\"] = title  # sadece dosya adÄ±\n",
        "        metadatas.append(meta)\n",
        "    return ids, metadatas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5bITRt02b-F"
      },
      "source": [
        "* Ã¶nceden hazÄ±rlanmÄ±ÅŸ metin parÃ§alarÄ±nÄ± (chunkâ€™larÄ±), metadata bilgilerini ve IDâ€™leri ChromaDB koleksiyonuna eklemek ve eklemeden Ã¶nce ve sonra koleksiyonun kaÃ§ kayÄ±t iÃ§erdiÄŸini kullanÄ±cÄ±ya bildirmektir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRltPZ4g2FKe"
      },
      "outputs": [],
      "source": [
        "def add_document_to_collection(ids, metadatas, text_chunksinTokens, chroma_collection):\n",
        "  print(\"Before inserting, the size of the collection: \", chroma_collection.count())\n",
        "  chroma_collection.add(ids=ids, metadatas= metadatas, documents=text_chunksinTokens)\n",
        "  print(\"After inserting, the size of the collection: \", chroma_collection.count())\n",
        "  return chroma_collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fHl1SGh2qSw"
      },
      "source": [
        "* ChromaDB koleksiyonundan bir sorguya (query) en yakÄ±n belgeleri (documents) ve onlarÄ±n ilgili metadata'larÄ±nÄ±, mesafeleriyle birlikte geri getirmektir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjTKcwJE2dvV"
      },
      "outputs": [],
      "source": [
        "def retrieveDocs(chroma_collection, query, n_results=15, return_only_docs=False):\n",
        "    results = chroma_collection.query(query_texts=[query],\n",
        "                                      include= [ \"documents\",\"metadatas\",'distances' ],\n",
        "                                      n_results=n_results)\n",
        "\n",
        "    if return_only_docs:\n",
        "        return results['documents'][0]\n",
        "    else:\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAUVtBLa3QU5"
      },
      "source": [
        "* Getilecek olan ilgili metinlerin metadata bilgileri ve iÃ§erikleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8TGzl7h29Y2"
      },
      "outputs": [],
      "source": [
        "def show_results(results, return_only_docs=False):\n",
        "\n",
        "  if return_only_docs:\n",
        "    retrieved_documents = results\n",
        "    if len(retrieved_documents) == 0:\n",
        "      print(\"No results found.\")\n",
        "      return\n",
        "    for i, doc in enumerate(retrieved_documents):\n",
        "      print(f\"Document {i+1}:\")\n",
        "      print(\"\\tDocument Text: \")\n",
        "      display(to_markdown(doc));\n",
        "  else:\n",
        "      retrieved_documents = results['documents'][0]\n",
        "      if len(retrieved_documents) == 0:\n",
        "          print(\"No results found.\")\n",
        "          return\n",
        "      retrieved_documents_metadata = results['metadatas'][0]\n",
        "      retrieved_documents_distances = results['distances'][0]\n",
        "      print(\"------- retreived documents -------\\n\")\n",
        "\n",
        "      for i, doc in enumerate(retrieved_documents):\n",
        "          print(f\"Document {i+1}:\")\n",
        "          print(\"\\tDocument Text: \")\n",
        "          display(to_markdown(doc));\n",
        "          print(f\"\\tDocument Source: {retrieved_documents_metadata[i]['document']}\")\n",
        "          print(f\"\\tDocument Source Type: {retrieved_documents_metadata[i]['category']}\")\n",
        "          print(f\"\\tDocument Distance: {retrieved_documents_distances[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk83G8ax37ly"
      },
      "source": [
        "load_multiple_pdfs_to_ChromaDB(...) fonksiyonu:\n",
        "\n",
        "    * KullanÄ±cÄ±dan birden fazla PDF dosyasÄ± alÄ±r\n",
        "\n",
        "    * Her PDFâ€™yi parÃ§alara ayÄ±rÄ±r (chunk)\n",
        "\n",
        "    * Her chunk'Ä± token bazlÄ± olarak iÅŸler\n",
        "\n",
        "    * Embeddingâ€™lerini hazÄ±rlar\n",
        "\n",
        "    * Metadata ile birlikte ChromaDBâ€™ye kaydeder\n",
        "\n",
        "    * TÃ¼m sÃ¼reci tek bir Ã§aÄŸrÄ± ile yÃ¶netir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keDtyizCLmGc"
      },
      "outputs": [],
      "source": [
        "def expand_page_numbers(original_chunks, tokenized_chunks, original_page_numbers):\n",
        "    expanded = []\n",
        "    char_index = 0\n",
        "    for i, orig_chunk in enumerate(original_chunks):\n",
        "        chunk_length = len(orig_chunk)\n",
        "        count = 0\n",
        "        while char_index < len(tokenized_chunks) and count < chunk_length:\n",
        "            expanded.append(original_page_numbers[i])\n",
        "            count += len(tokenized_chunks[char_index])\n",
        "            char_index += 1\n",
        "    # EÄŸer hala eksik varsa kalanlarÄ± son sayfayla doldur\n",
        "    while len(expanded) < len(tokenized_chunks):\n",
        "        expanded.append(original_page_numbers[-1])\n",
        "    return expanded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhhV_qr73Vwe"
      },
      "outputs": [],
      "source": [
        "def load_multiple_pdfs_to_ChromaDB(collection_name,sentence_transformer_model,\n",
        "                                   chromaDB_path):\n",
        "\n",
        "  collection_name= collection_name\n",
        "  category= \"Journal Paper\"\n",
        "  sentence_transformer_model=sentence_transformer_model\n",
        "  embedding_function= embedding_functions.SentenceTransformerEmbeddingFunction(model_name=sentence_transformer_model)\n",
        "  chroma_client, chroma_collection = create_chroma_client(collection_name, embedding_function, chromaDB_path)\n",
        "  current_id = chroma_collection.count()\n",
        "  file_names = upload_multiple_files()\n",
        "  for file_name in file_names:\n",
        "    print(f\"Document: {file_name} is being processed to be added to the {chroma_collection.name} {chroma_collection.count()}\")\n",
        "    print(f\"current_id: {current_id} \")\n",
        "    pdf_texts = convert_PDF_Text(file_name)\n",
        "    text_chunksinChar, heading_titles = convert_Page_ChunkinChar_with_pages(pdf_texts)\n",
        "    text_chunksinTokens = convert_Chunk_Token(text_chunksinChar, sentence_transformer_model)\n",
        "    adjusted_page_numbers = None\n",
        "    ids, metadatas = add_meta_data(text_chunksinTokens, file_name, category, current_id, adjusted_page_numbers)\n",
        "\n",
        "    current_id = current_id + len(text_chunksinTokens)\n",
        "    chroma_collection = add_document_to_collection(ids, metadatas, text_chunksinTokens, chroma_collection)\n",
        "    print(f\"Document: {file_name} added to the collection: {chroma_collection.count()}\")\n",
        "  return  chroma_client, chroma_collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwthwkl4MVzy"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV5Xf3_e4FG0"
      },
      "outputs": [],
      "source": [
        "chroma_client, chroma_collection= load_multiple_pdfs_to_ChromaDB(collection_name,sentence_transformer_model, chromaDB_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5Ix8uVnbQsg"
      },
      "outputs": [],
      "source": [
        "sentence_transformer_model = \"paraphrase-multilingual-mpnet-base-v2\"\n",
        "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=sentence_transformer_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqjCZ40CQias"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# ChromaDB dizinini kontrol et\n",
        "if os.path.exists(chromaDB_path):\n",
        "    print(\"ðŸ“‚ ChromaDB klasÃ¶r iÃ§eriÄŸi:\")\n",
        "    for item in os.listdir(chromaDB_path):\n",
        "        print(\" -\", item)\n",
        "else:\n",
        "    print(\"âŒ Belirtilen dizin mevcut deÄŸil:\", chromaDB_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAtH1juAZmAw"
      },
      "outputs": [],
      "source": [
        "\"\"\"# 2ï¸âƒ£ Var olan Chroma verisini baÄŸlamak:\n",
        "chromaDB_path = '/content/drive/MyDrive/RAG_heading_chunks'  # veya ChromaDBData2\n",
        "print(chromaDB_path)\n",
        "\n",
        "chroma_client = PersistentClient(path=chromaDB_path, settings=Settings())\n",
        "\n",
        "# 3ï¸âƒ£ AynÄ± collection adÄ±nÄ± kullan (Ã¶rnek: Papers)\n",
        "chroma_collection = chroma_client.get_collection(\"Papers_heading_chunks_NURAN\", embedding_function=embedding_function)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TflqcCuJ7wNd"
      },
      "outputs": [],
      "source": [
        "query = \"Erken YetiÅŸkin StatÃ¼sÃ¼ Riski\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_JEJRDod8AOA"
      },
      "outputs": [],
      "source": [
        "retrieved_documents=retrieveDocs(chroma_collection, query, 15)\n",
        "show_results(retrieved_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9edY7OLM9JjJ"
      },
      "outputs": [],
      "source": [
        "!ls \"{chromaDB_path}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPMPCMQL9NTm"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "# Disconnect from the runtime\n",
        "#!kill -9 -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyc1rrN69Ub2"
      },
      "outputs": [],
      "source": [
        "chroma_collection.get(['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kWUlZwy97CF"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6_CAb9t-BU6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh1NK1Q3-DMe"
      },
      "outputs": [],
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1Jmgkrc-Glw"
      },
      "outputs": [],
      "source": [
        "def generate_LLM_answer(prompt, context, chat):\n",
        "    full_prompt = f\"\"\"\n",
        "[BAÄžLAM]:\n",
        "{context}\n",
        "\n",
        "[SORU]:\n",
        "{prompt}\n",
        "\"\"\"\n",
        "    response = chat.send_message(full_prompt)\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ-E2HJu85QM"
      },
      "outputs": [],
      "source": [
        "\"\"\"def generateAnswer_with_source(RAG_LLM, chroma_collection, query, n_results=15):\n",
        "    results = retrieveDocs(chroma_collection, query, n_results=n_results)\n",
        "    chunks = results[\"documents\"][0]\n",
        "    metadatas = results[\"metadatas\"][0]\n",
        "\n",
        "    context_text = \"\\n\".join(chunks)\n",
        "    answer = generate_LLM_answer(query, context_text, RAG_LLM)\n",
        "\n",
        "    # KaynaklarÄ±n tÄ±klanabilir HTML formatÄ±nÄ± oluÅŸturalÄ±m\n",
        "    unique_links = set()\n",
        "    for m in metadatas:\n",
        "        source = m.get(\"source\", \"\")\n",
        "        label = f\"{m.get('document', '')}\"\n",
        "        if \"page\" in m:\n",
        "            label += f\" (sayfa {m['page']})\"\n",
        "        unique_links.add(f'<a href=\"{source}\" target=\"_blank\">{label}</a>')\n",
        "\n",
        "    final_answer = f\"{answer}\\n\\n<b>Kaynaklar:</b><br>\" + \"<br>\".join(unique_links)\n",
        "    return final_answer\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujc5e4H6-J-F"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai # Explicitly import genai here\n",
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GEMINIAPI3')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTvx4xbpPtA1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6G5zqHQ-L2Y"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "Sen, Ã¼stÃ¼n zekalÄ± Ã§ocuklarÄ±n sosyal geliÅŸimi konusunda uzmanlaÅŸmÄ±ÅŸ bir yapay zeka asistansÄ±n. GÃ¶rev alanÄ±n, bu Ã§ocuklarÄ±n arkadaÅŸlÄ±k iliÅŸkileri, yalnÄ±zlÄ±k hissi, duygusal ihtiyaÃ§larÄ± ve sosyal uyum sÃ¼reÃ§leri gibi konularda, ebeveynlere ve eÄŸitimcilere bilimsel kaynaklara dayalÄ± olarak rehberlik etmektir.\n",
        "\n",
        "Ana Kurallar:\n",
        "        *Sadece sana saÄŸlanan kaynak belgelerinde (RAG iÃ§eriklerinde) aÃ§Ä±kÃ§a yer alan bilgilere dayalÄ± cevap Ã¼ret.\n",
        "\n",
        "        *Kaynakta aÃ§Ä±k bilgi yoksa ÅŸu ifadeyi kullan:\n",
        "            \"Bu konuda elimde yeterli bilgi bulunmuyor.\"\n",
        "\n",
        "        *CevaplarÄ±nÄ± aÃ§Ä±k, sade ve profesyonel bir TÃ¼rkÃ§e ile yaz.\n",
        "\n",
        "        *Gerekirse maddeler halinde, bazen ise aÃ§Ä±klayÄ±cÄ± paragraflarla cevap ver.\n",
        "\n",
        "        *\"ÃœstÃ¼n zekalÄ±\" yerine daima \"Ã¼stÃ¼n yetenekli\" ifadesini kullan.\n",
        "\n",
        "        *Cevaplarda Ã¼stÃ¼n yetenekli Ã§ocuklar hakkÄ±nda olumsuz yargÄ± iÃ§eren, damgalayÄ±cÄ± ya da genelleyici ifadelerden kaÃ§Ä±n (Ã¶rneÄŸin: \"alÄ±ÅŸÄ±lmadÄ±k\", \"tuhaf\", \"sorunlu\" gibi kelimeler kullanÄ±lmaz).\n",
        "\n",
        "        *  **\"SaÄŸlanan kaynaklara gÃ¶re\"** gibi ifadeler yerine ÅŸu kalÄ±bÄ± kullan: **\"Bilimsel kaynaklara gÃ¶re\"**.\n",
        "\n",
        "        *Bilimsel kaynaklara gÃ¶re\" ifadesini kullan. â€œSaÄŸlanan iÃ§erikâ€, â€œverilen metinâ€ gibi kalÄ±plardan kaÃ§Ä±n.\n",
        "        KullanÄ±cÄ±nÄ±n kaynaklara eriÅŸimi olmadÄ±ÄŸÄ±nÄ± varsay. CevaplarÄ± buna gÃ¶re sade ve anlaÅŸÄ±lÄ±r sun.\n",
        "\n",
        "        * EÄŸer kullanÄ±cÄ± sorusu, Ã¼stÃ¼n yetenekli Ã§ocuklarla ilgili deÄŸilse,\n",
        "      hiÃ§bir aÃ§Ä±klama yapmadan aÅŸaÄŸÄ±daki cevabÄ± ver:\n",
        "      \"Ben Ã¼stÃ¼n yetenekli Ã§ocuklarÄ±n sosyal geliÅŸimi konusunda uzmanlaÅŸmÄ±ÅŸ bir yapay zekÃ¢ asistanÄ±yÄ±m. LÃ¼tfen bu alana dair bir soru sorun.\"\n",
        "\n",
        "        *Kesin, duygusal ya da cesur yÃ¶nlendirmelerden kaÃ§Ä±n. Ã–zellikle ÅŸu tÃ¼r ifadeler kullanÄ±lmamaya dikkat:\n",
        "            - \"ÃœstÃ¼n yetenekli Ã§ocuÄŸunuzun yalnÄ±z kalmasÄ±nÄ± destekleyin\"\n",
        "            - \"Kendinizi suÃ§lu hissetmeyin\"\n",
        "            - \"Her ÅŸey yoluna girecek\"\n",
        "            - \"Bu Ã§ok normal\" gibi genellemelere yer verme.\n",
        "\n",
        "Format TalimatÄ±:\n",
        "        *YanÄ±tlar, aÅŸaÄŸÄ±daki Ã¶rneklere uygun olacak ÅŸekilde yapÄ±landÄ±rÄ±lmalÄ±dÄ±r. LLMâ€™in vereceÄŸi cevaplar:\n",
        "\n",
        "        *Net bir baÅŸlÄ±k iÃ§ermeli\n",
        "\n",
        "        *GerektiÄŸinde aÃ§Ä±klamalÄ± paragraflar kullanÄ±lmalÄ±\n",
        "\n",
        "        *GerektiÄŸinde madde iÅŸaretleriyle yapÄ±landÄ±rÄ±lmalÄ±\n",
        "\n",
        "        *SonuÃ§ cÃ¼mlesi ile iÃ§erik toparlanmalÄ±\n",
        "\n",
        "\n",
        "ðŸ§ª Few-Shot Ã–rnek #1\n",
        "Soru:\n",
        "ÃœstÃ¼n yetenekli Ã§ocuÄŸum diÄŸer Ã§ocuklarla oynamak istemiyor, bu yalnÄ±zlÄ±k onun geliÅŸimini olumsuz etkiler mi?\n",
        "\n",
        "YanÄ±t:\n",
        "\n",
        "ÃœstÃ¼n Yetenekli Ã‡ocuklarda Sosyal YalnÄ±zlÄ±k ve Etkileri\n",
        "Bilimsel kaynaklara gÃ¶re, Ã¼stÃ¼n yetenekli Ã§ocuklar yaÅŸÄ±tlarÄ±yla ortak ilgi alanlarÄ± geliÅŸtirmekte zorlandÄ±klarÄ±nda sosyal etkileÅŸimlerden uzaklaÅŸabilirler. Bu durum yalnÄ±zlÄ±k hissini artÄ±rabilir ve sosyal beceri geliÅŸimini olumsuz yÃ¶nde etkileyebilir.\n",
        "\n",
        "YalnÄ±zlÄ±k eÄŸilimini azaltmak iÃ§in aÅŸaÄŸÄ±daki stratejiler Ã¶nerilmektedir:\n",
        "\n",
        "Ä°lgi alanÄ±na uygun sosyal ortamlar yaratÄ±n: Bilim kulÃ¼pleri, sanat atÃ¶lyeleri gibi yapÄ±lar, Ã§ocuÄŸun entelektÃ¼el dÃ¼zeyine hitap eden ortamlardÄ±r.\n",
        "\n",
        "Duygusal ifadeyi teÅŸvik edin: GÃ¼nlÃ¼k tutma, resim Ã§izme, hikÃ¢ye anlatma gibi araÃ§larla duygularÄ±nÄ± ifade etmesine yardÄ±mcÄ± olun.\n",
        "\n",
        "Birebir iliÅŸkileri destekleyin: BÃ¼yÃ¼k gruplar yerine bireysel arkadaÅŸlÄ±klar daha gÃ¼venli ve anlamlÄ± olabilir.\n",
        "\n",
        "SonuÃ§ olarak, Ã¼stÃ¼n yetenekli Ã§ocuklarÄ±n sosyal geliÅŸimi iÃ§in uygun ortamlarÄ±n saÄŸlanmasÄ± yalnÄ±zlÄ±k riskini azaltabilir.\n",
        "\n",
        "\n",
        "\n",
        "ðŸ§ª Few-Shot Ã–rnek #2\n",
        "Soru:\n",
        "ÃœstÃ¼n yetenekli bir Ã¶ÄŸrencim sÄ±nÄ±fta sÃ¼rekli liderlik etmeye Ã§alÄ±ÅŸÄ±yor. DiÄŸer Ã§ocuklarla Ã§atÄ±ÅŸma yaÅŸÄ±yor. Ne yapmalÄ±yÄ±m?\n",
        "\n",
        "YanÄ±t:\n",
        "\n",
        "ÃœstÃ¼n Yetenekli Ã‡ocuklarda Liderlik EÄŸilimleri ve SÄ±nÄ±f Ä°Ã§i Denge\n",
        "Bilimsel kaynaklara gÃ¶re, Ã¼stÃ¼n yetenekli Ã§ocuklar yÃ¼ksek sorumluluk duygusu ve giriÅŸkenlik gibi Ã¶zellikleri nedeniyle liderlik rolÃ¼nÃ¼ benimseme eÄŸilimindedir. Ancak bu durum, sÄ±nÄ±f iÃ§inde akranlarÄ±yla Ã§atÄ±ÅŸmalara neden olabilir.\n",
        "\n",
        "EÄŸitmenlerin bu eÄŸilimleri dengelemesi iÃ§in Ã¶neriler:\n",
        "\n",
        "Grup iÃ§i rol dÃ¶nÃ¼ÅŸÃ¼mleri saÄŸlayÄ±n: Her Ã¶ÄŸrencinin zaman zaman lider, takipÃ§i veya gÃ¶zlemci olduÄŸu etkinlikler planlayarak eÅŸit katÄ±lÄ±m teÅŸvik edilmelidir.\n",
        "\n",
        "Empati geliÅŸtirme etkinlikleri yapÄ±n: Oyunlar ve drama etkinlikleri Ã§ocuklarÄ±n baÅŸkalarÄ±nÄ±n bakÄ±ÅŸ aÃ§Ä±larÄ±nÄ± anlamalarÄ±na yardÄ±mcÄ± olur.\n",
        "\n",
        "Olumlu liderlik modelleri gÃ¶sterin: SaygÄ±lÄ±, dinlemeye aÃ§Ä±k ve iÅŸ birliÄŸine dayalÄ± liderlik davranÄ±ÅŸlarÄ± Ã¼zerine sÄ±nÄ±f iÃ§i konuÅŸmalar yapÄ±labilir.\n",
        "\n",
        "SonuÃ§ olarak, liderlik becerilerinin yapÄ±landÄ±rÄ±lmÄ±ÅŸ yollarla yÃ¶nlendirilmesi, sosyal uyumu gÃ¼Ã§lendirebilir.\n",
        "\n",
        "\n",
        "-----\n",
        "\n",
        "Her cevabÄ±nda yukarÄ±daki ilkeleri uygula. Sadece saÄŸlanan iÃ§eriklere gÃ¼ven. Tahmin veya kiÅŸisel yorum yapma. Kaynak yoksa dÃ¼rÃ¼stÃ§e belirt.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iTGv_Kc-E-M"
      },
      "outputs": [],
      "source": [
        "def build_chatBot(system_instruction):\n",
        "  model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=system_instruction,\n",
        "                                generation_config=genai.types.GenerationConfig(\n",
        "        temperature=0.3,\n",
        "        top_p=0.95,\n",
        "        top_k=70\n",
        "    ))\n",
        "  chat = model.start_chat(history=[])\n",
        "  return chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tmURCG1BN6F"
      },
      "outputs": [],
      "source": [
        "RAG_LLM = build_chatBot(system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO6mK-RcBVsk"
      },
      "outputs": [],
      "source": [
        "# Verify collection properties\n",
        "print(f\"Collection name: {chroma_collection.name}\")  # Access the name attribute directly\n",
        "print(f\"Number of documents in collection: {chroma_collection.count()}\")\n",
        "\n",
        "# List all collections in the client\n",
        "print(\"All collections in ChromaDB client:\")\n",
        "for collection in chroma_client.list_collections():\n",
        "    print(collection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSv_wTlGBjvh"
      },
      "outputs": [],
      "source": [
        "def summarize_collection(chroma_collection):\n",
        "  summary = [] # Initialize summary as a list\n",
        "  print(\"Summarizing the collection...\")\n",
        "  # Verify collection properties\n",
        "  print(f\"\\t Collection name: {chroma_collection.name}\")  # Access the name attribute directly\n",
        "  print(f\"\\t Number of document chunks in collection: {chroma_collection.count()}\")\n",
        "  summary.append(f\"Collection name: {chroma_collection.name}\") # Append to the list\n",
        "  summary.append(f\"Number of document chunks in collection: {chroma_collection.count()}\")\n",
        "  # Print distinct metadata \"document\" for each chunk in the collection\n",
        "  print(\"\\t Distinct 'document' metadata in the collection:\")\n",
        "  distinct_documents = set()  # Use a set to store unique document names\n",
        "\n",
        "  # Iterate over chunks in the collection\n",
        "  for chunk_id in range(chroma_collection.count()):\n",
        "      metadata = chroma_collection.get([str(chunk_id)])['metadatas'][0]  # Get metadata for the chunk\n",
        "      document_name = metadata.get(\"document\", \"Unknown\")  # Get document metadata; default to \"Unknown\" if not present\n",
        "      distinct_documents.add(document_name)  # Add document name to set for uniqueness\n",
        "\n",
        "  # Print all distinct document names\n",
        "  summary.append(\"Documents:\")\n",
        "  for document_name in distinct_documents:\n",
        "      print(\"\\t \",document_name)\n",
        "      summary.append(document_name) # Append to the list\n",
        "\n",
        "  print(\"Collection summarization completed.\")\n",
        "\n",
        "  # Join the list elements into a single string\n",
        "  summary_string = \"\\n \".join(summary)\n",
        "  return summary_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFNsytyHBmqT"
      },
      "outputs": [],
      "source": [
        "s=summarize_collection(chroma_collection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTG1y9PPBsEl"
      },
      "outputs": [],
      "source": [
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsQAkgy3Spfp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"outputs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bD_FPB3MB5if"
      },
      "outputs": [],
      "source": [
        "%pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLmd0-3Wlduq"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import CrossEncoder, SentenceTransformer, util\n",
        "import gradio as gr\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('â€¢', '  *')\n",
        "    return Markdown('> ' + text.replace('\\n', '\\n> '))\n",
        "\n",
        "# Model initialization\n",
        "reranker_model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
        "similarity_model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
        "\n",
        "# Reranking with metadata\n",
        "def rerank_chunks_with_metadata(query, chunks, metadatas, top_k=5):\n",
        "    if len(chunks) == 0:\n",
        "        return [], [], []\n",
        "\n",
        "    pairs = [(query, chunk) for chunk in chunks]\n",
        "    scores = reranker_model.predict(pairs)\n",
        "\n",
        "    scored = sorted(zip(chunks, metadatas, scores), key=lambda x: x[2], reverse=True)\n",
        "    top_chunks = [c for c, _, _ in scored[:top_k]]\n",
        "    top_metadatas = [m for _, m, _ in scored[:top_k]]\n",
        "    top_scores = [s for _, _, s in scored[:top_k]]\n",
        "\n",
        "    return top_chunks, top_metadatas, top_scores\n",
        "\n",
        "\n",
        "# Core answer generation\n",
        "def generateAnswer(RAG_LLM, chroma_collection, query, n_results=15, only_response=True):\n",
        "    # 1. ChromaDB'den belgeleri getir\n",
        "    results = retrieveDocs(chroma_collection, query, n_results=n_results, return_only_docs=False)\n",
        "    chunks = results[\"documents\"][0]\n",
        "    metadatas = results[\"metadatas\"][0]\n",
        "\n",
        "    # 2. Reranking: CrossEncoder kullan\n",
        "    reranked_chunks, reranked_metadatas, reranked_scores = rerank_chunks_with_metadata(query, chunks, metadatas, top_k=5)\n",
        "    context = \"\\n\".join(reranked_chunks)\n",
        "\n",
        "    # 3. LLM ile cevap Ã¼ret\n",
        "    output = generate_LLM_answer(query, context, RAG_LLM)\n",
        "\n",
        "    # 4. Cosine similarity hesapla\n",
        "    embedding_answer = similarity_model.encode(output, convert_to_tensor=True)\n",
        "    embedding_chunks = similarity_model.encode(reranked_chunks, convert_to_tensor=True)\n",
        "    cos_similarities = util.cos_sim(embedding_answer, embedding_chunks)\n",
        "\n",
        "    # 5. En yÃ¼ksek skorlarÄ± logla\n",
        "    print(\"ðŸ§ª Cosine Similarity SkorlarÄ±:\")\n",
        "    for i, score in enumerate(cos_similarities[0]):\n",
        "        print(f\"Chunk {i+1} | Cosine Sim: {score.item():.4f} | Skor: {reranked_scores[i]:.4f}\")\n",
        "        print(f\"â†’ {reranked_chunks[i][:80]}...\\n\")\n",
        "\n",
        "    max_sim = cos_similarities.max().item()\n",
        "\n",
        "    # 6. En iyi metadata bilgisi\n",
        "    best_meta = reranked_metadatas[0]\n",
        "    doc = best_meta.get(\"document\", \"Unknown.pdf\")\n",
        "    heading = best_meta.get(\"heading\", \"\")\n",
        "\n",
        "    # 7. YÄ±ldÄ±zlarÄ± temizle\n",
        "    output = output.replace(\"***\", \"\").replace(\"**\", \"\").replace(\"*\", \"\")\n",
        "\n",
        "    # 8. YanÄ±t formatÄ± + kaynak + skor bilgisi\n",
        "\n",
        "    output_with_source = output\n",
        "    output_with_source += f\"\\n\\nðŸ“˜ Kaynak: {doc}\"\n",
        "    if heading:\n",
        "        output_with_source += f\" â€“ {heading}\"\n",
        "    output_with_source += f\"\\nðŸ“Š En yÃ¼ksek reranker skoru: {reranked_scores[0]:.4f}\"\n",
        "    output_with_source += f\"\\nðŸ“ˆ En yÃ¼ksek cosine similarity: {max_sim:.4f}\"\n",
        "\n",
        "    # 9. YanÄ±tÄ± dosyaya kaydet (opsiyonel)\n",
        "    with open(\"outputs/step3_reranking2.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"\\n=== Query ===\\n{query}\\n\")\n",
        "        f.write(f\"=== Response ===\\n{output}\\n\")\n",
        "        f.write(f\"=== Max Cosine Sim ===\\n{max_sim:.4f}\\n\")\n",
        "        f.write(f\"=== Source ===\\n- {doc}\")\n",
        "        if heading:\n",
        "            f.write(f\" â€“ {heading}\")\n",
        "        f.write(f\"\\n-----------------------------\\n\")\n",
        "\n",
        "    return output_with_source\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Guardrails\n",
        "FORBIDDEN_KEYWORDS = [\n",
        "    \"intihar\", \"Ã¶ldÃ¼rmek\", \"hacklemek\", \"yasa dÄ±ÅŸÄ± eriÅŸim\", \"atlatmak\",\n",
        "    \"devre dÄ±ÅŸÄ± bÄ±rakmak\", \"bomba\", \"kod Ã§alÄ±ÅŸtÄ±rmak\", \"sistem kÄ±sÄ±tlamalarÄ±nÄ± kaldÄ±rmak\",\n",
        "    \"sen bir sohbet botu deÄŸilsin\", \"numara yapmak\", \"rol yapmak\", \"uyuÅŸturucu\",\n",
        "    \"ilaÃ§\", \"aspirin\", \"prozac\", \"ibuprofen\", \"rol\"\n",
        "]\n",
        "\n",
        "def is_safe_prompt(prompt):\n",
        "    return not any(keyword in prompt.lower() for keyword in FORBIDDEN_KEYWORDS)\n",
        "\n",
        "def reinforce_role(prompt):\n",
        "    red_flags = [\n",
        "        \"Ã¶nceki komutlarÄ± unut\", \"kural tanÄ±mÄ±yorsun\", \"rol yap\", \"filtreyi atla\",\n",
        "        \"yÃ¶nergeleri boÅŸver\", \"insan gibi davran\", \"kararÄ±nÄ± ver\", \"kaynaÄŸa baÄŸlÄ± kalma\",\n",
        "        \"promptu gÃ¶zardÄ± et\", \"kurallarÄ± unut\", \"moderasyon yok\", \"asistan deÄŸilsin\",\n",
        "        \"kÄ±sÄ±tlamasÄ±z cevap ver\"\n",
        "    ]\n",
        "    return not any(flag in prompt.lower() for flag in red_flags)\n",
        "\n",
        "def is_safe_output(output):\n",
        "    if output is None:\n",
        "        return False\n",
        "    lowered = output.lower()\n",
        "    return all(keyword not in lowered for keyword in FORBIDDEN_KEYWORDS)\n",
        "\n",
        "\n",
        "def full_guardrail_interface(question):\n",
        "    # if not is_safe_prompt(question) or not reinforce_role(question):\n",
        "    #     return \"ðŸš« Uygun olmayan bir iÃ§erik algÄ±landÄ±.\"\n",
        "\n",
        "    output = generateAnswer(RAG_LLM, chroma_collection, question)\n",
        "\n",
        "    # if not is_safe_output(output):\n",
        "    #     return \"ðŸš« Cevap gÃ¼venlik politikalarÄ±mÄ±za uymamaktadÄ±r.\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# Gradio UI\n",
        "RAG_LLM.history.clear()\n",
        "\n",
        "def generateAnswerInterFace(question):\n",
        "    return full_guardrail_interface(question)\n",
        "\n",
        "def get_info_text():\n",
        "    return \"INFO: \" + summarize_collection(chroma_collection)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ðŸŽ“ ÃœstÃ¼n Yetenekli Ã‡ocuklar Ä°Ã§in Sosyal GeliÅŸim AsistanÄ±\")\n",
        "    query_txt = gr.Textbox(label=\"Enter your question here:\", placeholder=\"Bir soru yazÄ±n...\", lines=3)\n",
        "    answer_txt = gr.Textbox(label=\"Answer:\", placeholder=\"Answer will be displayed here\", value=\"ðŸ‘‹ Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim?\", lines=15)\n",
        "    btn = gr.Button(\"Generate Answer\")\n",
        "    info_txt = gr.Textbox(get_info_text(), label=\"Info\")\n",
        "    btn.click(fn=generateAnswerInterFace, inputs=query_txt, outputs=answer_txt)\n",
        "\n",
        "demo.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28eKSsoobnEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}