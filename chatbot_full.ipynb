{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yavuzssvr19/moodle-chatbot/blob/main/chatbot_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9hRlkpvuJOF"
      },
      "outputs": [],
      "source": [
        "%pip install chromadb --quiet\n",
        "%pip install sentence_transformers --quiet\n",
        "%pip install pypdf --quiet\n",
        "%pip install langchain --quiet\n",
        "%pip install tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MHdIhvvdu46s"
      },
      "outputs": [],
      "source": [
        "\n",
        "import langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
        "\n",
        "\n",
        "from pypdf import PdfReader\n",
        "\n",
        "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
        "from chromadb import Client, PersistentClient\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1QJ1RmwRtKP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYKYEf8EbnFV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chromaDB_path = '/content/drive/MyDrive/RAG_heading_chunks'"
      ],
      "metadata": {
        "id": "Gp2oPVpv_C1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDH8Rck9v22X"
      },
      "outputs": [],
      "source": [
        "#Klasör varsa kullanıcıdan izin alarak içeriğini temizler.\n",
        "# Temiz veri deposu başlatmak için gerekli\n",
        "\n",
        "def delete_all_files_and_folders(chromaDB_path):\n",
        "  # verdiğin klasör yolu var mı yok mu kontrol eder.\n",
        "  if os.path.exists(chromaDB_path):\n",
        "    print(f\"The directory '{chromaDB_path}' already exists.\")\n",
        "    permission = input(\"Do you want to delete all the files and folders in this directory? (y/n): \")\n",
        "    #y yazarsa silinsin\n",
        "    if permission == \"y\":\n",
        "      shutil.rmtree(chromaDB_path)\n",
        "      print(f\"All files and folders in '{chromaDB_path}' have been deleted.\")\n",
        "    else:\n",
        "      print(\"No action taken.\")\n",
        "  else:\n",
        "    print(f\"The directory '{chromaDB_path}' does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agbhEiPowEfu"
      },
      "outputs": [],
      "source": [
        "# Check if the chromadb_path exists or not. If so, delete all the files and folders in chromadb_path. But before deleting get the permission from the user.\n",
        "delete_all_files_and_folders(chromaDB_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub55w7rBwI4x"
      },
      "outputs": [],
      "source": [
        "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
        "from chromadb import Client, PersistentClient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM2OCZuBxDRD"
      },
      "source": [
        "collection_name: Oluşturulacak veya yüklenecek koleksiyonun adı\n",
        "\n",
        "embedding_function: Embedding (vektörleştirme) fonksiyonu (örneğin: SentenceTransformers gibi)\n",
        "\n",
        "chromaDB_path: Eğer belirtilirse Chroma'nın verileri bu dizine kalıcı olarak kaydedilecek; belirtilmezse geçici bellek içinde tutulur.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAmI2rqSDyPy"
      },
      "source": [
        "| Parametre            | Anlamı                | Ne işe yarar?                                        |\n",
        "| -------------------- | --------------------- | ---------------------------------------------------- |\n",
        "| `collection_name`    | Koleksiyon adı        | Belge koleksiyonu tanımlar veya yükler               |\n",
        "| `embedding_function` | Vektörleştirme işlevi | Metni embedding'e çevirir                            |\n",
        "| `chromaDB_path`      | Kayıt yolu            | Verileri kalıcı mı, geçici mi saklayacağını belirler |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOlMVv7LEk3F"
      },
      "source": [
        "# create_chroma_client\n",
        " ChromaDB istemcisini (client) oluşturur ve bir koleksiyon (collection) yükler veya oluşturur.\n",
        "\n",
        "**Ne Zaman Kullanılır?**\n",
        "- RAG sisteminde PDF metinlerini işledikten sonra embedding’leri bir vektör veritabanına (ChromaDB) kaydetmek istersin.\n",
        "\n",
        "- Bu fonksiyon, ChromaDB’yi ya kalıcı olarak (örneğin Google Drive klasörüne) ya da geçici olarak (RAM içinde) başlatmanı sağlar.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb import Client, PersistentClient\n",
        "from chromadb.config import Settings, DEFAULT_TENANT, DEFAULT_DATABASE\n",
        "\n",
        "def create_chroma_client(collection_name, embedding_function, chromaDB_path=None):\n",
        "    if chromaDB_path:\n",
        "        chroma_client = PersistentClient(\n",
        "            path=chromaDB_path,\n",
        "            settings=Settings(),\n",
        "            tenant=DEFAULT_TENANT,\n",
        "            database=DEFAULT_DATABASE\n",
        "        )\n",
        "    else:\n",
        "        chroma_client = Client()\n",
        "\n",
        "    chroma_collection = chroma_client.get_or_create_collection(\n",
        "        name=collection_name,\n",
        "        embedding_function=embedding_function\n",
        "    )\n",
        "    return chroma_client, chroma_collection\n"
      ],
      "metadata": {
        "id": "-UC-WNkG7RWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from chromadb import PersistentClient\n",
        "from chromadb.config import Settings\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# Yeni ve yazılabilir bir klasör yolu belirle\n",
        "#chromaDB_path = \"/content/chroma_clean_workspace\"  # RAM içinde\n",
        "chromaDB_path = '/content/drive/MyDrive/RAG_heading_chunks'\n",
        "\n",
        "# Önce varsa silip temizle\n",
        "if os.path.exists(chromaDB_path):\n",
        "    shutil.rmtree(chromaDB_path)\n",
        "os.makedirs(chromaDB_path, exist_ok=True)\n",
        "\n",
        "# Embedding fonksiyonu tanımla\n",
        "sentence_transformer_model = \"paraphrase-multilingual-mpnet-base-v2\"\n",
        "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=sentence_transformer_model\n",
        ")\n",
        "\n",
        "# Yeni client başlat\n",
        "chroma_client = PersistentClient(path=chromaDB_path, settings=Settings())\n",
        "\n",
        "# Yeni koleksiyon oluştur\n",
        "collection_name = \"Papers_heading_chunks_BERNA\"\n",
        "chroma_collection = chroma_client.get_or_create_collection(\n",
        "    name=collection_name,\n",
        "    embedding_function=embedding_function\n",
        ")\n",
        "\n",
        "print(\"✅ Yeni koleksiyon başarıyla oluşturuldu:\", chroma_collection.name)\n"
      ],
      "metadata": {
        "id": "DN1U_a9T6aot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKVtz9wRw82E"
      },
      "outputs": [],
      "source": [
        "#Bu isim, ChromaDB içinde bir belge koleksiyonunu tanımlamak için kullanılır.\n",
        "#bu collection, PDF’lerden çıkarılmış chunklara ait vektör verilerini saklayacak.\n",
        "#collection_name = \"Papers_heading_chunks\"\n",
        "\n",
        "#Bu satırda embedding için kullanılacak modelin ismi belirleniyor.\n",
        "#sentence_transformer_model=\"paraphrase-multilingual-mpnet-base-v2\"\n",
        "\n",
        "#embedding fonksiyonu tanımlanıyor\n",
        "#Bu fonksiyon, her metin parçasını yukarıda belirlenen modeli kullanarak vektöre dönüştürür.\n",
        "#embedding_function= embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "#    model_name=sentence_transformer_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_bMfIdTe_nX"
      },
      "outputs": [],
      "source": [
        "from chromadb import PersistentClient\n",
        "from chromadb.config import Settings, DEFAULT_TENANT, DEFAULT_DATABASE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QibT24-x3pJ"
      },
      "outputs": [],
      "source": [
        "#Daha önce tanımlanmış create_chroma_client() fonksiyonunu çağırır ve dönen iki değeri chroma_client ve chroma_collection olarak saklar.\n",
        "chroma_client, chroma_collection = create_chroma_client(collection_name,\n",
        "                                                        embedding_function,\n",
        "                                                        chromaDB_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chroma istemcisinden tüm koleksiyonları listele\n",
        "for collection in chroma_client.list_collections():\n",
        "    print(collection.name)\n"
      ],
      "metadata": {
        "id": "tWXM2BuC3DfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"✅ Koleksiyon adı:\", chroma_collection.name)\n",
        "print(\"✅ Chunk sayısı:\", chroma_collection.count())\n"
      ],
      "metadata": {
        "id": "AZj7I3ny7cq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M31n3VF5yect"
      },
      "source": [
        "# upload_multiple_files()\n",
        " Kullanıcının Colab arayüzü üzerinden birden fazla dosya seçip yüklemesini sağlar ve yüklenen tüm dosyaların isimlerini bir liste halinde döndürür."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsW_YmCJyJ01"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "def upload_multiple_files():\n",
        "  uploaded = files.upload()\n",
        "  file_names = list()\n",
        "  for fn in uploaded.keys():\n",
        "    #print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "    file_names.append(fn)\n",
        "  return file_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgRagzNUzN7q"
      },
      "outputs": [],
      "source": [
        "#Google Colab arayüzünde bir dosya yükleme penceresi açar.\n",
        "#file_names = upload_multiple_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZbG77QxJTeX"
      },
      "source": [
        "# convert_PDF_Text()\n",
        "-  Bir PDF dosyasını sayfa sayfa okuyup, her sayfadaki metni çıkarmaktır.\n",
        "- Her sayfanın metnini bir liste elemanı olarak saklar ve boş sayfaları filtreler.\n",
        "\n",
        ".extract_text(): Sayfadaki metni çıkarır.\n",
        "\n",
        ".strip(): Başında ve sonundaki boşluk karakterlerini siler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkkTAZYpyjwI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_PDF_Text(pdf_path):\n",
        "  reader = PdfReader(pdf_path)\n",
        "  pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
        "  # Filter the empty strings\n",
        "  pdf_texts = [text for text in pdf_texts if text]\n",
        "  print(\"Document: \",pdf_path,\" chunk size: \", len(pdf_texts))\n",
        "  return pdf_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmxeXbDoKg32"
      },
      "source": [
        "# split_by_headings(pdf_texts)\n",
        "PDF'den çıkarılmış düz metinleri, başlıklara göre bölmek\n",
        "📌 Örneğin: \"1. Giriş\", \"2.1 Sosyal Gelişim\", \"Bölüm 3\", \"Sonuç\" gibi başlıklar yakalanır ve o başlıktan itibaren gelen içerik bir parça (chunk) olur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js9BPoVnMsVx"
      },
      "outputs": [],
      "source": [
        "def split_by_headings(pdf_texts):\n",
        "    all_text = \"\\n\".join(pdf_texts)\n",
        "    lines = all_text.split(\"\\n\")\n",
        "    split_points = [i for i, line in enumerate(lines) if re.match(r\"^\\s*(\\d+(\\.\\d+)*|Bölüm \\d+|Giriş|Sonuç)\", line, re.IGNORECASE)]\n",
        "\n",
        "    if not split_points:\n",
        "        # fallback: başlık bulunamadıysa tüm metni tek parça döndür\n",
        "        return [all_text.strip()]\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(len(split_points)):\n",
        "        start = split_points[i]\n",
        "        end = split_points[i + 1] if i + 1 < len(split_points) else len(lines)\n",
        "        section = \"\\n\".join(lines[start:end]).strip()\n",
        "        if section:\n",
        "            chunks.append(section)\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFYDUriby04p"
      },
      "outputs": [],
      "source": [
        "def convert_Page_ChunkinChar_with_pages(pdf_texts, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Heading-aware + character-based chunking:\n",
        "    Önce başlıklara göre ayırır, ardından karakter limitine göre chunk’lar üretir.\n",
        "    Sayfa numarası bilgisi vermez.\n",
        "    \"\"\"\n",
        "    character_splitter = RecursiveCharacterTextSplitter(\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "\n",
        "    # Heading bazlı bölümleri al (senin split_by_headings fonksiyonunla)\n",
        "    heading_sections = split_by_headings(pdf_texts)\n",
        "\n",
        "    all_chunks = []\n",
        "    for section in heading_sections:\n",
        "        sub_chunks = character_splitter.split_text(section)\n",
        "        all_chunks.extend(sub_chunks)\n",
        "\n",
        "    print(f\"Toplam karakter + heading-aware chunk sayısı: {len(all_chunks)}\")\n",
        "    return all_chunks, None  # page_numbers yerine None döner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8KAi0X-1OmH"
      },
      "source": [
        "* daha önce karakter bazlı olarak bölünmüş metinleri token bazlı daha hassas parçalara ayırmak ve LLM veya embedding modellerinin token sınırlarına daha uygun hale getirmekti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRVFa53BzySt"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_Chunk_Token(text_chunksinChar, sentence_transformer_model,\n",
        "                        chunk_overlap=64, tokens_per_chunk=128):\n",
        "  token_splitter = SentenceTransformersTokenTextSplitter(\n",
        "      chunk_overlap=chunk_overlap,\n",
        "      model_name=sentence_transformer_model,\n",
        "      tokens_per_chunk=tokens_per_chunk)\n",
        "\n",
        "  text_chunksinTokens = []\n",
        "  for text in text_chunksinChar:\n",
        "      text_chunksinTokens += token_splitter.split_text(text)\n",
        "  print(f\"\\nTotal number of token chunks: {len(text_chunksinTokens)}\")\n",
        "  return text_chunksinTokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YwBan2w2ATW"
      },
      "source": [
        "Bu fonksiyonun amacı, ChromaDB’ye eklenecek her metin parçası (chunk) için:\n",
        "\n",
        "    * Benzersiz bir kimlik (ID) oluşturmak\n",
        "\n",
        "    * Her parçaya belgeye özel metadata (başlık ve kategori gibi) eklemek\n",
        "\n",
        "böylece daha sonra belge bazlı filtreleme ve sorgulama yapabilmeni sağlamaktır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_bjQ1g61RuN"
      },
      "outputs": [],
      "source": [
        "def add_meta_data(text_chunks, title, category, initial_id, headings=None):\n",
        "    ids = [str(i + initial_id) for i in range(len(text_chunks))]\n",
        "    metadatas = []\n",
        "    for i in range(len(text_chunks)):\n",
        "        meta = {\n",
        "            'document': title,\n",
        "            'category': category\n",
        "        }\n",
        "        if headings:\n",
        "            meta[\"heading\"] = headings[i]\n",
        "            meta[\"source\"] = f\"{title} – {headings[i]}\"  # 👈 metin formatında kaynak\n",
        "        else:\n",
        "            meta[\"source\"] = title  # sadece dosya adı\n",
        "        metadatas.append(meta)\n",
        "    return ids, metadatas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5bITRt02b-F"
      },
      "source": [
        "* önceden hazırlanmış metin parçalarını (chunk’ları), metadata bilgilerini ve ID’leri ChromaDB koleksiyonuna eklemek ve eklemeden önce ve sonra koleksiyonun kaç kayıt içerdiğini kullanıcıya bildirmektir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRltPZ4g2FKe"
      },
      "outputs": [],
      "source": [
        "def add_document_to_collection(ids, metadatas, text_chunksinTokens, chroma_collection):\n",
        "  print(\"Before inserting, the size of the collection: \", chroma_collection.count())\n",
        "  chroma_collection.add(ids=ids, metadatas= metadatas, documents=text_chunksinTokens)\n",
        "  print(\"After inserting, the size of the collection: \", chroma_collection.count())\n",
        "  return chroma_collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fHl1SGh2qSw"
      },
      "source": [
        "* ChromaDB koleksiyonundan bir sorguya (query) en yakın belgeleri (documents) ve onların ilgili metadata'larını, mesafeleriyle birlikte geri getirmektir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjTKcwJE2dvV"
      },
      "outputs": [],
      "source": [
        "def retrieveDocs(chroma_collection, query, n_results=15, return_only_docs=False):\n",
        "    results = chroma_collection.query(query_texts=[query],\n",
        "                                      include= [ \"documents\",\"metadatas\",'distances' ],\n",
        "                                      n_results=n_results)\n",
        "\n",
        "    if return_only_docs:\n",
        "        return results['documents'][0]\n",
        "    else:\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAUVtBLa3QU5"
      },
      "source": [
        "* Getilecek olan ilgili metinlerin metadata bilgileri ve içerikleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8TGzl7h29Y2"
      },
      "outputs": [],
      "source": [
        "def show_results(results, return_only_docs=False):\n",
        "\n",
        "  if return_only_docs:\n",
        "    retrieved_documents = results\n",
        "    if len(retrieved_documents) == 0:\n",
        "      print(\"No results found.\")\n",
        "      return\n",
        "    for i, doc in enumerate(retrieved_documents):\n",
        "      print(f\"Document {i+1}:\")\n",
        "      print(\"\\tDocument Text: \")\n",
        "      display(to_markdown(doc));\n",
        "  else:\n",
        "      retrieved_documents = results['documents'][0]\n",
        "      if len(retrieved_documents) == 0:\n",
        "          print(\"No results found.\")\n",
        "          return\n",
        "      retrieved_documents_metadata = results['metadatas'][0]\n",
        "      retrieved_documents_distances = results['distances'][0]\n",
        "      print(\"------- retreived documents -------\\n\")\n",
        "\n",
        "      for i, doc in enumerate(retrieved_documents):\n",
        "          print(f\"Document {i+1}:\")\n",
        "          print(\"\\tDocument Text: \")\n",
        "          display(to_markdown(doc));\n",
        "          print(f\"\\tDocument Source: {retrieved_documents_metadata[i]['document']}\")\n",
        "          print(f\"\\tDocument Source Type: {retrieved_documents_metadata[i]['category']}\")\n",
        "          print(f\"\\tDocument Distance: {retrieved_documents_distances[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk83G8ax37ly"
      },
      "source": [
        "load_multiple_pdfs_to_ChromaDB(...) fonksiyonu:\n",
        "\n",
        "    * Kullanıcıdan birden fazla PDF dosyası alır\n",
        "\n",
        "    * Her PDF’yi parçalara ayırır (chunk)\n",
        "\n",
        "    * Her chunk'ı token bazlı olarak işler\n",
        "\n",
        "    * Embedding’lerini hazırlar\n",
        "\n",
        "    * Metadata ile birlikte ChromaDB’ye kaydeder\n",
        "\n",
        "    * Tüm süreci tek bir çağrı ile yönetir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keDtyizCLmGc"
      },
      "outputs": [],
      "source": [
        "def expand_page_numbers(original_chunks, tokenized_chunks, original_page_numbers):\n",
        "    expanded = []\n",
        "    char_index = 0\n",
        "    for i, orig_chunk in enumerate(original_chunks):\n",
        "        chunk_length = len(orig_chunk)\n",
        "        count = 0\n",
        "        while char_index < len(tokenized_chunks) and count < chunk_length:\n",
        "            expanded.append(original_page_numbers[i])\n",
        "            count += len(tokenized_chunks[char_index])\n",
        "            char_index += 1\n",
        "    # Eğer hala eksik varsa kalanları son sayfayla doldur\n",
        "    while len(expanded) < len(tokenized_chunks):\n",
        "        expanded.append(original_page_numbers[-1])\n",
        "    return expanded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhhV_qr73Vwe"
      },
      "outputs": [],
      "source": [
        "def load_multiple_pdfs_to_ChromaDB(collection_name,sentence_transformer_model,\n",
        "                                   chromaDB_path):\n",
        "\n",
        "  collection_name= collection_name\n",
        "  category= \"Journal Paper\"\n",
        "  sentence_transformer_model=sentence_transformer_model\n",
        "  embedding_function= embedding_functions.SentenceTransformerEmbeddingFunction(model_name=sentence_transformer_model)\n",
        "  chroma_client, chroma_collection = create_chroma_client(collection_name, embedding_function, chromaDB_path)\n",
        "  current_id = chroma_collection.count()\n",
        "  file_names = upload_multiple_files()\n",
        "  for file_name in file_names:\n",
        "    print(f\"Document: {file_name} is being processed to be added to the {chroma_collection.name} {chroma_collection.count()}\")\n",
        "    print(f\"current_id: {current_id} \")\n",
        "    pdf_texts = convert_PDF_Text(file_name)\n",
        "    text_chunksinChar, heading_titles = convert_Page_ChunkinChar_with_pages(pdf_texts)\n",
        "    text_chunksinTokens = convert_Chunk_Token(text_chunksinChar, sentence_transformer_model)\n",
        "    adjusted_page_numbers = None\n",
        "    ids, metadatas = add_meta_data(text_chunksinTokens, file_name, category, current_id, adjusted_page_numbers)\n",
        "\n",
        "    current_id = current_id + len(text_chunksinTokens)\n",
        "    chroma_collection = add_document_to_collection(ids, metadatas, text_chunksinTokens, chroma_collection)\n",
        "    print(f\"Document: {file_name} added to the collection: {chroma_collection.count()}\")\n",
        "  return  chroma_client, chroma_collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwthwkl4MVzy"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV5Xf3_e4FG0"
      },
      "outputs": [],
      "source": [
        "chroma_client, chroma_collection= load_multiple_pdfs_to_ChromaDB(collection_name,sentence_transformer_model, chromaDB_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5Ix8uVnbQsg"
      },
      "outputs": [],
      "source": [
        "sentence_transformer_model = \"paraphrase-multilingual-mpnet-base-v2\"\n",
        "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=sentence_transformer_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqjCZ40CQias"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# ChromaDB dizinini kontrol et\n",
        "if os.path.exists(chromaDB_path):\n",
        "    print(\"📂 ChromaDB klasör içeriği:\")\n",
        "    for item in os.listdir(chromaDB_path):\n",
        "        print(\" -\", item)\n",
        "else:\n",
        "    print(\"❌ Belirtilen dizin mevcut değil:\", chromaDB_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAtH1juAZmAw"
      },
      "outputs": [],
      "source": [
        "\"\"\"# 2️⃣ Var olan Chroma verisini bağlamak:\n",
        "chromaDB_path = '/content/drive/MyDrive/RAG_heading_chunks'  # veya ChromaDBData2\n",
        "print(chromaDB_path)\n",
        "\n",
        "chroma_client = PersistentClient(path=chromaDB_path, settings=Settings())\n",
        "\n",
        "# 3️⃣ Aynı collection adını kullan (örnek: Papers)\n",
        "chroma_collection = chroma_client.get_collection(\"Papers_heading_chunks_NURAN\", embedding_function=embedding_function)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TflqcCuJ7wNd"
      },
      "outputs": [],
      "source": [
        "query = \"Erken Yetişkin Statüsü Riski\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_JEJRDod8AOA"
      },
      "outputs": [],
      "source": [
        "retrieved_documents=retrieveDocs(chroma_collection, query, 15)\n",
        "show_results(retrieved_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9edY7OLM9JjJ"
      },
      "outputs": [],
      "source": [
        "!ls \"{chromaDB_path}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPMPCMQL9NTm"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "# Disconnect from the runtime\n",
        "#!kill -9 -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyc1rrN69Ub2"
      },
      "outputs": [],
      "source": [
        "chroma_collection.get(['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kWUlZwy97CF"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6_CAb9t-BU6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh1NK1Q3-DMe"
      },
      "outputs": [],
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1Jmgkrc-Glw"
      },
      "outputs": [],
      "source": [
        "def generate_LLM_answer(prompt, context, chat):\n",
        "    full_prompt = f\"\"\"\n",
        "[BAĞLAM]:\n",
        "{context}\n",
        "\n",
        "[SORU]:\n",
        "{prompt}\n",
        "\"\"\"\n",
        "    response = chat.send_message(full_prompt)\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ-E2HJu85QM"
      },
      "outputs": [],
      "source": [
        "\"\"\"def generateAnswer_with_source(RAG_LLM, chroma_collection, query, n_results=15):\n",
        "    results = retrieveDocs(chroma_collection, query, n_results=n_results)\n",
        "    chunks = results[\"documents\"][0]\n",
        "    metadatas = results[\"metadatas\"][0]\n",
        "\n",
        "    context_text = \"\\n\".join(chunks)\n",
        "    answer = generate_LLM_answer(query, context_text, RAG_LLM)\n",
        "\n",
        "    # Kaynakların tıklanabilir HTML formatını oluşturalım\n",
        "    unique_links = set()\n",
        "    for m in metadatas:\n",
        "        source = m.get(\"source\", \"\")\n",
        "        label = f\"{m.get('document', '')}\"\n",
        "        if \"page\" in m:\n",
        "            label += f\" (sayfa {m['page']})\"\n",
        "        unique_links.add(f'<a href=\"{source}\" target=\"_blank\">{label}</a>')\n",
        "\n",
        "    final_answer = f\"{answer}\\n\\n<b>Kaynaklar:</b><br>\" + \"<br>\".join(unique_links)\n",
        "    return final_answer\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujc5e4H6-J-F"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai # Explicitly import genai here\n",
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GEMINIAPI3')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTvx4xbpPtA1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6G5zqHQ-L2Y"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "Sen, üstün zekalı çocukların sosyal gelişimi konusunda uzmanlaşmış bir yapay zeka asistansın. Görev alanın, bu çocukların arkadaşlık ilişkileri, yalnızlık hissi, duygusal ihtiyaçları ve sosyal uyum süreçleri gibi konularda, ebeveynlere ve eğitimcilere bilimsel kaynaklara dayalı olarak rehberlik etmektir.\n",
        "\n",
        "Ana Kurallar:\n",
        "        *Sadece sana sağlanan kaynak belgelerinde (RAG içeriklerinde) açıkça yer alan bilgilere dayalı cevap üret.\n",
        "\n",
        "        *Kaynakta açık bilgi yoksa şu ifadeyi kullan:\n",
        "            \"Bu konuda elimde yeterli bilgi bulunmuyor.\"\n",
        "\n",
        "        *Cevaplarını açık, sade ve profesyonel bir Türkçe ile yaz.\n",
        "\n",
        "        *Gerekirse maddeler halinde, bazen ise açıklayıcı paragraflarla cevap ver.\n",
        "\n",
        "        *\"Üstün zekalı\" yerine daima \"üstün yetenekli\" ifadesini kullan.\n",
        "\n",
        "        *Cevaplarda üstün yetenekli çocuklar hakkında olumsuz yargı içeren, damgalayıcı ya da genelleyici ifadelerden kaçın (örneğin: \"alışılmadık\", \"tuhaf\", \"sorunlu\" gibi kelimeler kullanılmaz).\n",
        "\n",
        "        *  **\"Sağlanan kaynaklara göre\"** gibi ifadeler yerine şu kalıbı kullan: **\"Bilimsel kaynaklara göre\"**.\n",
        "\n",
        "        *Bilimsel kaynaklara göre\" ifadesini kullan. “Sağlanan içerik”, “verilen metin” gibi kalıplardan kaçın.\n",
        "        Kullanıcının kaynaklara erişimi olmadığını varsay. Cevapları buna göre sade ve anlaşılır sun.\n",
        "\n",
        "        * Eğer kullanıcı sorusu, üstün yetenekli çocuklarla ilgili değilse,\n",
        "      hiçbir açıklama yapmadan aşağıdaki cevabı ver:\n",
        "      \"Ben üstün yetenekli çocukların sosyal gelişimi konusunda uzmanlaşmış bir yapay zekâ asistanıyım. Lütfen bu alana dair bir soru sorun.\"\n",
        "\n",
        "        *Kesin, duygusal ya da cesur yönlendirmelerden kaçın. Özellikle şu tür ifadeler kullanılmamaya dikkat:\n",
        "            - \"Üstün yetenekli çocuğunuzun yalnız kalmasını destekleyin\"\n",
        "            - \"Kendinizi suçlu hissetmeyin\"\n",
        "            - \"Her şey yoluna girecek\"\n",
        "            - \"Bu çok normal\" gibi genellemelere yer verme.\n",
        "\n",
        "Format Talimatı:\n",
        "        *Yanıtlar, aşağıdaki örneklere uygun olacak şekilde yapılandırılmalıdır. LLM’in vereceği cevaplar:\n",
        "\n",
        "        *Net bir başlık içermeli\n",
        "\n",
        "        *Gerektiğinde açıklamalı paragraflar kullanılmalı\n",
        "\n",
        "        *Gerektiğinde madde işaretleriyle yapılandırılmalı\n",
        "\n",
        "        *Sonuç cümlesi ile içerik toparlanmalı\n",
        "\n",
        "\n",
        "🧪 Few-Shot Örnek #1\n",
        "Soru:\n",
        "Üstün yetenekli çocuğum diğer çocuklarla oynamak istemiyor, bu yalnızlık onun gelişimini olumsuz etkiler mi?\n",
        "\n",
        "Yanıt:\n",
        "\n",
        "Üstün Yetenekli Çocuklarda Sosyal Yalnızlık ve Etkileri\n",
        "Bilimsel kaynaklara göre, üstün yetenekli çocuklar yaşıtlarıyla ortak ilgi alanları geliştirmekte zorlandıklarında sosyal etkileşimlerden uzaklaşabilirler. Bu durum yalnızlık hissini artırabilir ve sosyal beceri gelişimini olumsuz yönde etkileyebilir.\n",
        "\n",
        "Yalnızlık eğilimini azaltmak için aşağıdaki stratejiler önerilmektedir:\n",
        "\n",
        "İlgi alanına uygun sosyal ortamlar yaratın: Bilim kulüpleri, sanat atölyeleri gibi yapılar, çocuğun entelektüel düzeyine hitap eden ortamlardır.\n",
        "\n",
        "Duygusal ifadeyi teşvik edin: Günlük tutma, resim çizme, hikâye anlatma gibi araçlarla duygularını ifade etmesine yardımcı olun.\n",
        "\n",
        "Birebir ilişkileri destekleyin: Büyük gruplar yerine bireysel arkadaşlıklar daha güvenli ve anlamlı olabilir.\n",
        "\n",
        "Sonuç olarak, üstün yetenekli çocukların sosyal gelişimi için uygun ortamların sağlanması yalnızlık riskini azaltabilir.\n",
        "\n",
        "\n",
        "\n",
        "🧪 Few-Shot Örnek #2\n",
        "Soru:\n",
        "Üstün yetenekli bir öğrencim sınıfta sürekli liderlik etmeye çalışıyor. Diğer çocuklarla çatışma yaşıyor. Ne yapmalıyım?\n",
        "\n",
        "Yanıt:\n",
        "\n",
        "Üstün Yetenekli Çocuklarda Liderlik Eğilimleri ve Sınıf İçi Denge\n",
        "Bilimsel kaynaklara göre, üstün yetenekli çocuklar yüksek sorumluluk duygusu ve girişkenlik gibi özellikleri nedeniyle liderlik rolünü benimseme eğilimindedir. Ancak bu durum, sınıf içinde akranlarıyla çatışmalara neden olabilir.\n",
        "\n",
        "Eğitmenlerin bu eğilimleri dengelemesi için öneriler:\n",
        "\n",
        "Grup içi rol dönüşümleri sağlayın: Her öğrencinin zaman zaman lider, takipçi veya gözlemci olduğu etkinlikler planlayarak eşit katılım teşvik edilmelidir.\n",
        "\n",
        "Empati geliştirme etkinlikleri yapın: Oyunlar ve drama etkinlikleri çocukların başkalarının bakış açılarını anlamalarına yardımcı olur.\n",
        "\n",
        "Olumlu liderlik modelleri gösterin: Saygılı, dinlemeye açık ve iş birliğine dayalı liderlik davranışları üzerine sınıf içi konuşmalar yapılabilir.\n",
        "\n",
        "Sonuç olarak, liderlik becerilerinin yapılandırılmış yollarla yönlendirilmesi, sosyal uyumu güçlendirebilir.\n",
        "\n",
        "\n",
        "-----\n",
        "\n",
        "Her cevabında yukarıdaki ilkeleri uygula. Sadece sağlanan içeriklere güven. Tahmin veya kişisel yorum yapma. Kaynak yoksa dürüstçe belirt.\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iTGv_Kc-E-M"
      },
      "outputs": [],
      "source": [
        "def build_chatBot(system_instruction):\n",
        "  model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=system_instruction,\n",
        "                                generation_config=genai.types.GenerationConfig(\n",
        "        temperature=0.3,\n",
        "        top_p=0.95,\n",
        "        top_k=70\n",
        "    ))\n",
        "  chat = model.start_chat(history=[])\n",
        "  return chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tmURCG1BN6F"
      },
      "outputs": [],
      "source": [
        "RAG_LLM = build_chatBot(system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO6mK-RcBVsk"
      },
      "outputs": [],
      "source": [
        "# Verify collection properties\n",
        "print(f\"Collection name: {chroma_collection.name}\")  # Access the name attribute directly\n",
        "print(f\"Number of documents in collection: {chroma_collection.count()}\")\n",
        "\n",
        "# List all collections in the client\n",
        "print(\"All collections in ChromaDB client:\")\n",
        "for collection in chroma_client.list_collections():\n",
        "    print(collection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSv_wTlGBjvh"
      },
      "outputs": [],
      "source": [
        "def summarize_collection(chroma_collection):\n",
        "  summary = [] # Initialize summary as a list\n",
        "  print(\"Summarizing the collection...\")\n",
        "  # Verify collection properties\n",
        "  print(f\"\\t Collection name: {chroma_collection.name}\")  # Access the name attribute directly\n",
        "  print(f\"\\t Number of document chunks in collection: {chroma_collection.count()}\")\n",
        "  summary.append(f\"Collection name: {chroma_collection.name}\") # Append to the list\n",
        "  summary.append(f\"Number of document chunks in collection: {chroma_collection.count()}\")\n",
        "  # Print distinct metadata \"document\" for each chunk in the collection\n",
        "  print(\"\\t Distinct 'document' metadata in the collection:\")\n",
        "  distinct_documents = set()  # Use a set to store unique document names\n",
        "\n",
        "  # Iterate over chunks in the collection\n",
        "  for chunk_id in range(chroma_collection.count()):\n",
        "      metadata = chroma_collection.get([str(chunk_id)])['metadatas'][0]  # Get metadata for the chunk\n",
        "      document_name = metadata.get(\"document\", \"Unknown\")  # Get document metadata; default to \"Unknown\" if not present\n",
        "      distinct_documents.add(document_name)  # Add document name to set for uniqueness\n",
        "\n",
        "  # Print all distinct document names\n",
        "  summary.append(\"Documents:\")\n",
        "  for document_name in distinct_documents:\n",
        "      print(\"\\t \",document_name)\n",
        "      summary.append(document_name) # Append to the list\n",
        "\n",
        "  print(\"Collection summarization completed.\")\n",
        "\n",
        "  # Join the list elements into a single string\n",
        "  summary_string = \"\\n \".join(summary)\n",
        "  return summary_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFNsytyHBmqT"
      },
      "outputs": [],
      "source": [
        "s=summarize_collection(chroma_collection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTG1y9PPBsEl"
      },
      "outputs": [],
      "source": [
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsQAkgy3Spfp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"outputs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bD_FPB3MB5if"
      },
      "outputs": [],
      "source": [
        "%pip install gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLmd0-3Wlduq"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import CrossEncoder, SentenceTransformer, util\n",
        "import gradio as gr\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('•', '  *')\n",
        "    return Markdown('> ' + text.replace('\\n', '\\n> '))\n",
        "\n",
        "# Model initialization\n",
        "reranker_model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
        "similarity_model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
        "\n",
        "# Reranking with metadata\n",
        "def rerank_chunks_with_metadata(query, chunks, metadatas, top_k=5):\n",
        "    if len(chunks) == 0:\n",
        "        return [], [], []\n",
        "\n",
        "    pairs = [(query, chunk) for chunk in chunks]\n",
        "    scores = reranker_model.predict(pairs)\n",
        "\n",
        "    scored = sorted(zip(chunks, metadatas, scores), key=lambda x: x[2], reverse=True)\n",
        "    top_chunks = [c for c, _, _ in scored[:top_k]]\n",
        "    top_metadatas = [m for _, m, _ in scored[:top_k]]\n",
        "    top_scores = [s for _, _, s in scored[:top_k]]\n",
        "\n",
        "    return top_chunks, top_metadatas, top_scores\n",
        "\n",
        "\n",
        "# Core answer generation\n",
        "def generateAnswer(RAG_LLM, chroma_collection, query, n_results=15, only_response=True):\n",
        "    # 1. ChromaDB'den belgeleri getir\n",
        "    results = retrieveDocs(chroma_collection, query, n_results=n_results, return_only_docs=False)\n",
        "    chunks = results[\"documents\"][0]\n",
        "    metadatas = results[\"metadatas\"][0]\n",
        "\n",
        "    # 2. Reranking: CrossEncoder kullan\n",
        "    reranked_chunks, reranked_metadatas, reranked_scores = rerank_chunks_with_metadata(query, chunks, metadatas, top_k=5)\n",
        "    context = \"\\n\".join(reranked_chunks)\n",
        "\n",
        "    # 3. LLM ile cevap üret\n",
        "    output = generate_LLM_answer(query, context, RAG_LLM)\n",
        "\n",
        "    # 4. Cosine similarity hesapla\n",
        "    embedding_answer = similarity_model.encode(output, convert_to_tensor=True)\n",
        "    embedding_chunks = similarity_model.encode(reranked_chunks, convert_to_tensor=True)\n",
        "    cos_similarities = util.cos_sim(embedding_answer, embedding_chunks)\n",
        "\n",
        "    # 5. En yüksek skorları logla\n",
        "    print(\"🧪 Cosine Similarity Skorları:\")\n",
        "    for i, score in enumerate(cos_similarities[0]):\n",
        "        print(f\"Chunk {i+1} | Cosine Sim: {score.item():.4f} | Skor: {reranked_scores[i]:.4f}\")\n",
        "        print(f\"→ {reranked_chunks[i][:80]}...\\n\")\n",
        "\n",
        "    max_sim = cos_similarities.max().item()\n",
        "\n",
        "    # 6. En iyi metadata bilgisi\n",
        "    best_meta = reranked_metadatas[0]\n",
        "    doc = best_meta.get(\"document\", \"Unknown.pdf\")\n",
        "    heading = best_meta.get(\"heading\", \"\")\n",
        "\n",
        "    # 7. Yıldızları temizle\n",
        "    output = output.replace(\"***\", \"\").replace(\"**\", \"\").replace(\"*\", \"\")\n",
        "\n",
        "    # 8. Yanıt formatı + kaynak + skor bilgisi\n",
        "\n",
        "    output_with_source = output\n",
        "    output_with_source += f\"\\n\\n📘 Kaynak: {doc}\"\n",
        "    if heading:\n",
        "        output_with_source += f\" – {heading}\"\n",
        "    output_with_source += f\"\\n📊 En yüksek reranker skoru: {reranked_scores[0]:.4f}\"\n",
        "    output_with_source += f\"\\n📈 En yüksek cosine similarity: {max_sim:.4f}\"\n",
        "\n",
        "    # 9. Yanıtı dosyaya kaydet (opsiyonel)\n",
        "    with open(\"outputs/step3_reranking2.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"\\n=== Query ===\\n{query}\\n\")\n",
        "        f.write(f\"=== Response ===\\n{output}\\n\")\n",
        "        f.write(f\"=== Max Cosine Sim ===\\n{max_sim:.4f}\\n\")\n",
        "        f.write(f\"=== Source ===\\n- {doc}\")\n",
        "        if heading:\n",
        "            f.write(f\" – {heading}\")\n",
        "        f.write(f\"\\n-----------------------------\\n\")\n",
        "\n",
        "    return output_with_source\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Guardrails\n",
        "FORBIDDEN_KEYWORDS = [\n",
        "    \"intihar\", \"öldürmek\", \"hacklemek\", \"yasa dışı erişim\", \"atlatmak\",\n",
        "    \"devre dışı bırakmak\", \"bomba\", \"kod çalıştırmak\", \"sistem kısıtlamalarını kaldırmak\",\n",
        "    \"sen bir sohbet botu değilsin\", \"numara yapmak\", \"rol yapmak\", \"uyuşturucu\",\n",
        "    \"ilaç\", \"aspirin\", \"prozac\", \"ibuprofen\", \"rol\"\n",
        "]\n",
        "\n",
        "def is_safe_prompt(prompt):\n",
        "    return not any(keyword in prompt.lower() for keyword in FORBIDDEN_KEYWORDS)\n",
        "\n",
        "def reinforce_role(prompt):\n",
        "    red_flags = [\n",
        "        \"önceki komutları unut\", \"kural tanımıyorsun\", \"rol yap\", \"filtreyi atla\",\n",
        "        \"yönergeleri boşver\", \"insan gibi davran\", \"kararını ver\", \"kaynağa bağlı kalma\",\n",
        "        \"promptu gözardı et\", \"kuralları unut\", \"moderasyon yok\", \"asistan değilsin\",\n",
        "        \"kısıtlamasız cevap ver\"\n",
        "    ]\n",
        "    return not any(flag in prompt.lower() for flag in red_flags)\n",
        "\n",
        "def is_safe_output(output):\n",
        "    if output is None:\n",
        "        return False\n",
        "    lowered = output.lower()\n",
        "    return all(keyword not in lowered for keyword in FORBIDDEN_KEYWORDS)\n",
        "\n",
        "\n",
        "def full_guardrail_interface(question):\n",
        "    # if not is_safe_prompt(question) or not reinforce_role(question):\n",
        "    #     return \"🚫 Uygun olmayan bir içerik algılandı.\"\n",
        "\n",
        "    output = generateAnswer(RAG_LLM, chroma_collection, question)\n",
        "\n",
        "    # if not is_safe_output(output):\n",
        "    #     return \"🚫 Cevap güvenlik politikalarımıza uymamaktadır.\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# Gradio UI\n",
        "RAG_LLM.history.clear()\n",
        "\n",
        "def generateAnswerInterFace(question):\n",
        "    return full_guardrail_interface(question)\n",
        "\n",
        "def get_info_text():\n",
        "    return \"INFO: \" + summarize_collection(chroma_collection)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🎓 Üstün Yetenekli Çocuklar İçin Sosyal Gelişim Asistanı\")\n",
        "    query_txt = gr.Textbox(label=\"Enter your question here:\", placeholder=\"Bir soru yazın...\", lines=3)\n",
        "    answer_txt = gr.Textbox(label=\"Answer:\", placeholder=\"Answer will be displayed here\", value=\"👋 Merhaba! Size nasıl yardımcı olabilirim?\", lines=15)\n",
        "    btn = gr.Button(\"Generate Answer\")\n",
        "    info_txt = gr.Textbox(get_info_text(), label=\"Info\")\n",
        "    btn.click(fn=generateAnswerInterFace, inputs=query_txt, outputs=answer_txt)\n",
        "\n",
        "demo.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28eKSsoobnEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}